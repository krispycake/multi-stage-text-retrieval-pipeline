{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30776,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install transformers datasets torch torchvision torchtext\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-04T12:57:51.335667Z","iopub.execute_input":"2024-10-04T12:57:51.336364Z","iopub.status.idle":"2024-10-04T12:58:04.947649Z","shell.execute_reply.started":"2024-10-04T12:57:51.336307Z","shell.execute_reply":"2024-10-04T12:58:04.946567Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.2)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (3.0.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (0.19.0)\nCollecting torchtext\n  Downloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl.metadata (7.9 kB)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.0)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (16.1.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.13.3)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision) (10.3.0)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nDownloading torchtext-0.18.0-cp310-cp310-manylinux1_x86_64.whl (2.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n\u001b[?25hInstalling collected packages: torchtext\nSuccessfully installed torchtext-0.18.0\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport torch\nfrom transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification\nfrom datasets import load_dataset\nimport random\nimport logging\n\n# Set random seed for reproducibility\nrandom.seed(42)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T12:58:04.949978Z","iopub.execute_input":"2024-10-04T12:58:04.950695Z","iopub.status.idle":"2024-10-04T12:58:09.650057Z","shell.execute_reply.started":"2024-10-04T12:58:04.950645Z","shell.execute_reply":"2024-10-04T12:58:09.649230Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Load datasets\nmax_samples = 10000  # Limit the number of samples for each dataset\n\nhotpotqa_data = load_dataset(\"BeIR/hotpotqa-generated-queries\", split=\"train\").select(range(max_samples))\nnq_data = load_dataset(\"BeIR/nq-generated-queries\", split=\"train\").select(range(max_samples))\nfiqa_data = load_dataset(\"BeIR/fiqa-generated-queries\", split=\"train\").select(range(max_samples))\n\n# Check the loaded datasets\nprint(hotpotqa_data)\nprint(nq_data)\nprint(fiqa_data)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T12:58:09.651346Z","iopub.execute_input":"2024-10-04T12:58:09.651960Z","iopub.status.idle":"2024-10-04T12:59:30.945787Z","shell.execute_reply.started":"2024-10-04T12:58:09.651914Z","shell.execute_reply":"2024-10-04T12:59:30.944772Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/14.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f92b8bb78e4f4fa69eabb41ba1bb8ee4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.jsonl.gz:   0%|          | 0.00/665M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d7bdfc3e75e641dfb4ccaf97ee74e466"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/5233329 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5bb9937a0f0c4c06986f0e18b1085caf"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/14.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d407c1cc056a4d879335f6c373d36111"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.jsonl.gz:   0%|          | 0.00/657M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb63ff585e5c4aacb5b630becf883297"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/7866640 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b9fd1387e5c44f7d93083e643e6a3249"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/14.0k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2e09c6da649f4626ba8038b7f5acc3b7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"train.jsonl.gz:   0%|          | 0.00/52.5M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e1bec3ebe064428aa612bf2ba2ea67cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/162444 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fef6c102b0544d6aaad159daa3c05fcb"}},"metadata":{}},{"name":"stdout","text":"Dataset({\n    features: ['_id', 'title', 'text', 'query'],\n    num_rows: 10000\n})\nDataset({\n    features: ['_id', 'title', 'text', 'query'],\n    num_rows: 10000\n})\nDataset({\n    features: ['_id', 'title', 'text', 'query'],\n    num_rows: 10000\n})\n","output_type":"stream"}]},{"cell_type":"code","source":"# Example of accessing relevance labels (if available)\nprint(hotpotqa_data[0])  # Print the first sample with query, passages, and relevance scores\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T12:59:30.948457Z","iopub.execute_input":"2024-10-04T12:59:30.948984Z","iopub.status.idle":"2024-10-04T12:59:30.956172Z","shell.execute_reply.started":"2024-10-04T12:59:30.948949Z","shell.execute_reply":"2024-10-04T12:59:30.955334Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"{'_id': '12', 'title': 'Anarchism', 'text': 'Anarchism is a political philosophy that advocates self-governed societies based on voluntary institutions. These are often described as stateless societies, although several authors have defined them more specifically as institutions based on non-hierarchical free associations. Anarchism holds the state to be undesirable, unnecessary and harmful.', 'query': 'anarchism defined'}\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define a function to preprocess data with relevance scores\ndef preprocess_data_with_relevance(data):\n    passages = []\n    queries = []\n    \n    for entry in data:\n        if 'text' in entry:\n            passages.append(entry['text'])\n        if 'query' in entry:\n            queries.append(entry['query'])\n            \n    return passages, queries\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T12:59:30.957346Z","iopub.execute_input":"2024-10-04T12:59:30.957667Z","iopub.status.idle":"2024-10-04T12:59:31.567486Z","shell.execute_reply.started":"2024-10-04T12:59:30.957633Z","shell.execute_reply":"2024-10-04T12:59:31.566410Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Assuming hotpotqa_data, nq_data, and fiqa_data are defined and loaded\n\n# Process each dataset separately\nhotpotqa_passages, hotpotqa_queries = preprocess_data_with_relevance(hotpotqa_data)\nnq_passages, nq_queries = preprocess_data_with_relevance(nq_data)\nfiqa_passages, fiqa_queries = preprocess_data_with_relevance(fiqa_data)\n\n# Check lengths of passages and queries\nprint(f\"HotpotQA - Passages: {len(hotpotqa_passages)}, Queries: {len(hotpotqa_queries)}\")\nprint(f\"NQ - Passages: {len(nq_passages)}, Queries: {len(nq_queries)}\")\nprint(f\"FIQA - Passages: {len(fiqa_passages)}, Queries: {len(fiqa_queries)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T12:59:31.568861Z","iopub.execute_input":"2024-10-04T12:59:31.569884Z","iopub.status.idle":"2024-10-04T12:59:33.358380Z","shell.execute_reply.started":"2024-10-04T12:59:31.569845Z","shell.execute_reply":"2024-10-04T12:59:33.357378Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"HotpotQA - Passages: 10000, Queries: 10000\nNQ - Passages: 10000, Queries: 10000\nFIQA - Passages: 10000, Queries: 10000\n","output_type":"stream"}]},{"cell_type":"code","source":"# Define a function to assign binary relevance scores\ndef assign_binary_relevance(queries, passages):\n    relevance_scores = []\n    passage_sets = [set(passage.lower().split()) for passage in passages]  # Convert passages to sets\n    \n    for query in queries:\n        query_set = set(query.lower().split())  # Convert query to set\n        scores = [1 if query_set.intersection(passage_set) else 0 for passage_set in passage_sets]\n        relevance_scores.append(scores)\n        \n    return relevance_scores\n\n\n# Generate binary relevance scores for each dataset\nhotpotqa_relevance_scores = assign_binary_relevance(hotpotqa_queries, hotpotqa_passages)\nnq_relevance_scores = assign_binary_relevance(nq_queries, nq_passages)\nfiqa_relevance_scores = assign_binary_relevance(fiqa_queries, fiqa_passages)\n\n# Check lengths after assignment\nprint(f\"HotpotQA Relevance Scores: {len(hotpotqa_relevance_scores)}\")\nprint(f\"NQ Relevance Scores: {len(nq_relevance_scores)}\")\nprint(f\"FIQA Relevance Scores: {len(fiqa_relevance_scores)}\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T12:59:33.359947Z","iopub.execute_input":"2024-10-04T12:59:33.360256Z","iopub.status.idle":"2024-10-04T13:02:01.167049Z","shell.execute_reply.started":"2024-10-04T12:59:33.360222Z","shell.execute_reply":"2024-10-04T13:02:01.165977Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"HotpotQA Relevance Scores: 10000\nNQ Relevance Scores: 10000\nFIQA Relevance Scores: 10000\n","output_type":"stream"}]},{"cell_type":"code","source":"# Load small embedding model\ntokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\nmodel = AutoModel.from_pretrained(\"sentence-transformers/all-MiniLM-L6-v2\")\n\n# Set device to GPU\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nmodel.to(device)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:02:01.168336Z","iopub.execute_input":"2024-10-04T13:02:01.168663Z","iopub.status.idle":"2024-10-04T13:02:04.166966Z","shell.execute_reply.started":"2024-10-04T13:02:01.168629Z","shell.execute_reply":"2024-10-04T13:02:04.165990Z"},"trusted":true},"execution_count":8,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f59e3f65574c475bb33985841456b48d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0afb9b62f19044888aaa69d6b9ece4b9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"99aa9c60a4a5447cad8475b2933d29d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c60d1ea509c84fd099c023e43f2493e8"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7797a92daa5d4650b6be17d7477f97d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b66c8c441ac34158b7b709d7ef887d98"}},"metadata":{}},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"BertModel(\n  (embeddings): BertEmbeddings(\n    (word_embeddings): Embedding(30522, 384, padding_idx=0)\n    (position_embeddings): Embedding(512, 384)\n    (token_type_embeddings): Embedding(2, 384)\n    (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n    (dropout): Dropout(p=0.1, inplace=False)\n  )\n  (encoder): BertEncoder(\n    (layer): ModuleList(\n      (0-5): 6 x BertLayer(\n        (attention): BertAttention(\n          (self): BertSdpaSelfAttention(\n            (query): Linear(in_features=384, out_features=384, bias=True)\n            (key): Linear(in_features=384, out_features=384, bias=True)\n            (value): Linear(in_features=384, out_features=384, bias=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n          (output): BertSelfOutput(\n            (dense): Linear(in_features=384, out_features=384, bias=True)\n            (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n            (dropout): Dropout(p=0.1, inplace=False)\n          )\n        )\n        (intermediate): BertIntermediate(\n          (dense): Linear(in_features=384, out_features=1536, bias=True)\n          (intermediate_act_fn): GELUActivation()\n        )\n        (output): BertOutput(\n          (dense): Linear(in_features=1536, out_features=384, bias=True)\n          (LayerNorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n          (dropout): Dropout(p=0.1, inplace=False)\n        )\n      )\n    )\n  )\n  (pooler): BertPooler(\n    (dense): Linear(in_features=384, out_features=384, bias=True)\n    (activation): Tanh()\n  )\n)"},"metadata":{}}]},{"cell_type":"code","source":"# Function to get embeddings for passages\ndef get_embeddings(passages, batch_size=64):\n    embeddings = []\n    for i in range(0, len(passages), batch_size):\n        batch_passages = passages[i:i + batch_size]\n        inputs = tokenizer(batch_passages, return_tensors='pt', truncation=True, padding=True, max_length=128)\n        inputs = {k: v.to(device) for k, v in inputs.items()}  # Move input tensors to GPU\n        with torch.no_grad():\n            embedding = model(**inputs).last_hidden_state.mean(dim=1).cpu()  # Move back to CPU after processing\n        embeddings.append(embedding)\n    \n    return torch.cat(embeddings)\n\n# Generate embeddings for HotpotQA passages\npassage_embeddings = get_embeddings(hotpotqa_passages)  # Use hotpotqa_passages\nprint(f\"HotpotQA Passage Embeddings Shape: {passage_embeddings.shape}\")","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:02:04.168173Z","iopub.execute_input":"2024-10-04T13:02:04.168652Z","iopub.status.idle":"2024-10-04T13:02:16.573118Z","shell.execute_reply.started":"2024-10-04T13:02:04.168616Z","shell.execute_reply":"2024-10-04T13:02:16.572140Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"HotpotQA Passage Embeddings Shape: torch.Size([10000, 384])\n","output_type":"stream"}]},{"cell_type":"code","source":"\nnum_passages = len(hotpotqa_passages)  # Use the processed passages\nnum_embeddings = passage_embeddings.shape[0]\n\n# Check if they match\nif num_passages == num_embeddings:\n    print(f\"The number of passages ({num_passages}) matches the number of embeddings ({num_embeddings}).\")\nelse:\n    print(f\"Mismatch: Number of passages is {num_passages}, but number of embeddings is {num_embeddings}.\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:02:16.576545Z","iopub.execute_input":"2024-10-04T13:02:16.577138Z","iopub.status.idle":"2024-10-04T13:02:16.583210Z","shell.execute_reply.started":"2024-10-04T13:02:16.577100Z","shell.execute_reply":"2024-10-04T13:02:16.582218Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"The number of passages (10000) matches the number of embeddings (10000).\n","output_type":"stream"}]},{"cell_type":"code","source":"\ndef rerank_passages(query, passages):\n    # Placeholder logic for reranking passages based on the query\n    scores = np.random.rand(len(passages))  # Example random scores\n    ranked_indices = np.argsort(-scores).tolist()  # Sort indices in descending order\n    return ranked_indices","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:02:16.584426Z","iopub.execute_input":"2024-10-04T13:02:16.584748Z","iopub.status.idle":"2024-10-04T13:02:16.601797Z","shell.execute_reply.started":"2024-10-04T13:02:16.584688Z","shell.execute_reply":"2024-10-04T13:02:16.600859Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Function to get relevance scores based on cosine similarity\ndef get_cosine_similarity_scores(query, passages, passage_embeddings):\n    query_embedding = get_embeddings([query])  # Get embedding for the query\n    scores = []\n    \n    for passage_embedding in passage_embeddings:\n        score = torch.nn.functional.cosine_similarity(query_embedding, passage_embedding.unsqueeze(0))  \n        scores.append(score.item())  # Get the score for each passage\n    \n    return scores\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:02:16.602991Z","iopub.execute_input":"2024-10-04T13:02:16.603360Z","iopub.status.idle":"2024-10-04T13:02:16.610286Z","shell.execute_reply.started":"2024-10-04T13:02:16.603317Z","shell.execute_reply":"2024-10-04T13:02:16.609275Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Example usage for HotpotQA dataset\nquery = \"what age do children with autism develop?\"\n\n# Ensure you are using the embeddings for the correct passages\ncosine_similarity_scores = get_cosine_similarity_scores(query, hotpotqa_passages, passage_embeddings)\n\n# Get the indices of the passages ranked by cosine similarity\nranked_indices_without_reranking = np.argsort(cosine_similarity_scores)[::-1]  # Sort by descending similarity\n\n# Top-k passages based on cosine similarity\ntop_k_passages_without_reranking = [hotpotqa_passages[idx] for idx in ranked_indices_without_reranking[:10]]\nprint(\"Top passages without ranking model (by cosine similarity):\")\nfor passage in top_k_passages_without_reranking:\n    print(passage[:50])  # Print only the first 50 characters of each passage\n    print(\"...\")\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:02:16.611551Z","iopub.execute_input":"2024-10-04T13:02:16.611906Z","iopub.status.idle":"2024-10-04T13:02:16.961568Z","shell.execute_reply.started":"2024-10-04T13:02:16.611870Z","shell.execute_reply":"2024-10-04T13:02:16.960518Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Top passages without ranking model (by cosine similarity):\nAutism is a neurodevelopmental disorder characteri\n...\nDevelopmental psychology is the scientific study o\n...\nKid Icarus, known in Japan as Light Mythology: Pal\n...\nLafora disease, also called Lafora progressive myo\n...\nA motor neuron disease (MND) is any of several neu\n...\nDown syndrome (DS or DNS), also known as trisomy 2\n...\nThe Kocher–Debré–Semelaigne syndrome is hypothyroi\n...\nDementia praecox (a \"premature dementia\" or \"preco\n...\nIn the 2011 census, Nepal's population was approxi\n...\nAn intelligence quotient (IQ) is a total score der\n...\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**\n    Evaluate the ranked passages using NDCG (Normalized Discounted Cumulative Gain).\n    \n    Parameters:\n    - ranked_passages: The indices of passages in the ranked order.\n    - relevance_scores: A list of relevance scores for each passage (higher is more relevant).\n    - k: Number of top passages to consider for NDCG calculation (default is 10).\n    \n    Returns:\n    - ndcg: The NDCG score for the top-k ranked passages.\n    **","metadata":{}},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.metrics import ndcg_score\n\ndef evaluate_ndcg_for_query(query, passages, relevance_scores):\n\n    y_true = np.array(relevance_scores)\n\n    # Assuming passages are fixed, generate y_score once\n    y_score = np.ones(len(passages))  # Example scoring for all passages\n\n    # Calculate NDCG score\n    ndcg = ndcg_score([y_true], [y_score])\n    return ndcg\n\ndef evaluate_ndcg_for_dataset(queries, passages, relevance_scores): #  Evaluate total NDCG for a dataset.\n  \n\n    total_ndcg = 0.0\n\n    # Use an optimized method to avoid redundant calculations\n    y_score = np.ones(len(passages))  # Precompute y_score once\n    \n    for rel_scores in relevance_scores:\n        y_true = np.array(rel_scores)\n        ndcg = ndcg_score([y_true], [y_score])\n        total_ndcg += ndcg\n\n    # Average the NDCG score over the number of queries\n    average_ndcg = total_ndcg / len(queries) if queries else 0.0\n    return average_ndcg\n\n","metadata":{"execution":{"iopub.status.busy":"2024-10-04T13:50:07.086065Z","iopub.execute_input":"2024-10-04T13:50:07.086486Z","iopub.status.idle":"2024-10-04T13:50:07.095615Z","shell.execute_reply.started":"2024-10-04T13:50:07.086443Z","shell.execute_reply":"2024-10-04T13:50:07.094588Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"\nhotpotqa_total_ndcg = evaluate_ndcg_for_dataset(hotpotqa_queries, hotpotqa_passages, hotpotqa_relevance_scores)\nhotpotqa_percentage = hotpotqa_total_ndcg * 100  \nnq_total_ndcg = evaluate_ndcg_for_dataset(nq_queries, nq_passages, nq_relevance_scores)\nnq_percentage = nq_total_ndcg * 100  \nfiqa_total_ndcg = evaluate_ndcg_for_dataset(fiqa_queries, fiqa_passages, fiqa_relevance_scores)\nfiqa_percentage = fiqa_total_ndcg * 100 \n\n\n#Calculate NDCG\naverage_ndcg_percentage = (hotpotqa_percentage + nq_percentage + fiqa_percentage) / 3\naverage_ndcg_decimal = average_ndcg_percentage / 100\nprint(f\"\\n NDCG@5: {average_ndcg_decimal:.2f}%\")","metadata":{"execution":{"iopub.status.busy":"2024-10-04T14:03:03.353772Z","iopub.execute_input":"2024-10-04T14:03:03.354505Z","iopub.status.idle":"2024-10-04T14:04:29.334251Z","shell.execute_reply.started":"2024-10-04T14:03:03.354462Z","shell.execute_reply":"2024-10-04T14:04:29.333303Z"},"trusted":true},"execution_count":36,"outputs":[{"name":"stdout","text":"\n NDCG@5: 0.93%\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}